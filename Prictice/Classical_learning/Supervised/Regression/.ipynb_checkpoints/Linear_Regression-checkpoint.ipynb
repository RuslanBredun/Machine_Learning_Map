{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a79716c8",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Linear Regression</h1> \n",
    "\n",
    "If you want to start machine learning, Linear regression is the best place to start. Linear Regression is a regression model, meaning, it’ll take features and predict a continuous output, eg : stock price,salary etc. Linear regression as the name says, finds a linear curve solution to every problem.\n",
    "\n",
    "## Basic Theory :\n",
    "LR allocates weight parameter, $\\Large \\beta_i$ (beta) for each of the training features $\\Large X_i$. The predicted output ($\\Large Y_i$) will be a linear function of features $\\Large X_i$ and $\\Large \\beta_i$ coefficients.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*GSAcN9G7stUJQbuOhu0HEg.png\" width=\"500\">\n",
    "\n",
    "\n",
    "During the start of training, each theta is randomly initialized. But during the training, we correct the $\\beta_i$ corresponding to each feature such that, the loss (metric of the deviation between expected and predicted output) is minimized. [Gradient descend algorithm](https://en.wikipedia.org/wiki/Gradient_descent) will be used to align the $\\beta_i$ values in the right direction. In the below diagram, each blue dots represent the training data and the blue line shows the derived solution.\n",
    "\n",
    "<img src=\"https://scipy-lectures.org/_images/sphx_glr_plot_linear_regression_001.png\" width=\"500\">\n",
    "\n",
    "### Loss function :\n",
    "In LR, we use [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error) as the metric of loss. The deviation of expected and actual outputs will be squared and sum up. Derivative of this loss will be used by gradient descend algorithm.\n",
    "\n",
    "### Advantages :\n",
    "- Easy and simple implementation.\n",
    "- Space complex solution.\n",
    "- Fast training.\n",
    "- Value of $\\beta_i$ coefficients gives an assumption of feature significance.\n",
    "\n",
    "### Disadvantages :\n",
    "- Applicable only if the solution is linear. In many real life scenarios, it may not be the case.\n",
    "- Algorithm assumes the input residuals (error) to be normal distributed, but may not be satisfied always.\n",
    "- Algorithm assumes input features to be mutually independent(no co-linearity).\n",
    "\n",
    "### Hyperparameters :\n",
    "- Regularization parameter $(λ)$ : Regularization is used to avoid over-fitting on the data. Higher the $(λ)$, higher will be regularization and the solution will be highly biased. Lower the $(λ)$, solution will be of high variance. An intermediate value is preferable.\n",
    "- learning rate $(α)$ : it estimates, by how much the $\\beta_i$ values should be corrected while applying gradient descend algorithm during training. $\\beta_i$ should also be a moderate value.\n",
    "\n",
    "### Assumptions for LR :\n",
    "- Linear relationship between the independent and dependent variables.\n",
    "- Training data to be homoskedastic, meaning the variance of the errors should be somewhat constant.\n",
    "- Independent variables should not be co-linear.\n",
    "\n",
    "### Colinearity & Outliers :\n",
    "Two features are said to be colinear when one feature can be linearly predicted from the other with somewhat accuracy.\n",
    "- colinearity will simply c the standard error and causes some significant features to become insignificant during training. Ideally, we should calculate the colinearity prior to training and keep only one feature from highly correlated feature sets.\n",
    "Outlier is another challenge faced during training. They are data-points that are extreme to normal observations and affects the accuracy of the model.\n",
    "\n",
    "- outliers inflates the error functions and affects the curve function and accuracy of the linear regression. Regularization (especially L1 ) can correct the outliers, by not allowing the θ parameters to change violently.\n",
    "-During Exploratory data analysis phase itself, we should take care of outliers and correct/eliminate them. Box-plot can be used for identifying them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c3ff8d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed moduls\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f28514",
   "metadata": {},
   "source": [
    "We will use simple dataset in scikit learn. If you already have an idea of the dataset you would like to use from the package, you can specify it. In the following example, we will import the diabetes dataset. This dataset contains data from diabetic patients and contains certain features such as their bmi, age , blood pressure and glucose levels which are useful in predicting the diabetes disease progression in patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5ef68b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.511817e-19</td>\n",
       "      <td>1.230790e-17</td>\n",
       "      <td>-2.245564e-16</td>\n",
       "      <td>-4.797570e-17</td>\n",
       "      <td>-1.381499e-17</td>\n",
       "      <td>3.918434e-17</td>\n",
       "      <td>-5.777179e-18</td>\n",
       "      <td>-9.042540e-18</td>\n",
       "      <td>9.293722e-17</td>\n",
       "      <td>1.130318e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.072256e-01</td>\n",
       "      <td>-4.464164e-02</td>\n",
       "      <td>-9.027530e-02</td>\n",
       "      <td>-1.123988e-01</td>\n",
       "      <td>-1.267807e-01</td>\n",
       "      <td>-1.156131e-01</td>\n",
       "      <td>-1.023071e-01</td>\n",
       "      <td>-7.639450e-02</td>\n",
       "      <td>-1.260971e-01</td>\n",
       "      <td>-1.377672e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.729927e-02</td>\n",
       "      <td>-4.464164e-02</td>\n",
       "      <td>-3.422907e-02</td>\n",
       "      <td>-3.665608e-02</td>\n",
       "      <td>-3.424784e-02</td>\n",
       "      <td>-3.035840e-02</td>\n",
       "      <td>-3.511716e-02</td>\n",
       "      <td>-3.949338e-02</td>\n",
       "      <td>-3.324559e-02</td>\n",
       "      <td>-3.317903e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.383060e-03</td>\n",
       "      <td>-4.464164e-02</td>\n",
       "      <td>-7.283766e-03</td>\n",
       "      <td>-5.670422e-03</td>\n",
       "      <td>-4.320866e-03</td>\n",
       "      <td>-3.819065e-03</td>\n",
       "      <td>-6.584468e-03</td>\n",
       "      <td>-2.592262e-03</td>\n",
       "      <td>-1.947171e-03</td>\n",
       "      <td>-1.077698e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.807591e-02</td>\n",
       "      <td>5.068012e-02</td>\n",
       "      <td>3.124802e-02</td>\n",
       "      <td>3.564379e-02</td>\n",
       "      <td>2.835801e-02</td>\n",
       "      <td>2.984439e-02</td>\n",
       "      <td>2.931150e-02</td>\n",
       "      <td>3.430886e-02</td>\n",
       "      <td>3.243232e-02</td>\n",
       "      <td>2.791705e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.107267e-01</td>\n",
       "      <td>5.068012e-02</td>\n",
       "      <td>1.705552e-01</td>\n",
       "      <td>1.320436e-01</td>\n",
       "      <td>1.539137e-01</td>\n",
       "      <td>1.987880e-01</td>\n",
       "      <td>1.811791e-01</td>\n",
       "      <td>1.852344e-01</td>\n",
       "      <td>1.335973e-01</td>\n",
       "      <td>1.356118e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age           sex           bmi            bp            s1  \\\n",
       "count  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02   \n",
       "mean  -2.511817e-19  1.230790e-17 -2.245564e-16 -4.797570e-17 -1.381499e-17   \n",
       "std    4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02   \n",
       "min   -1.072256e-01 -4.464164e-02 -9.027530e-02 -1.123988e-01 -1.267807e-01   \n",
       "25%   -3.729927e-02 -4.464164e-02 -3.422907e-02 -3.665608e-02 -3.424784e-02   \n",
       "50%    5.383060e-03 -4.464164e-02 -7.283766e-03 -5.670422e-03 -4.320866e-03   \n",
       "75%    3.807591e-02  5.068012e-02  3.124802e-02  3.564379e-02  2.835801e-02   \n",
       "max    1.107267e-01  5.068012e-02  1.705552e-01  1.320436e-01  1.539137e-01   \n",
       "\n",
       "                 s2            s3            s4            s5            s6  \n",
       "count  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  \n",
       "mean   3.918434e-17 -5.777179e-18 -9.042540e-18  9.293722e-17  1.130318e-17  \n",
       "std    4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  \n",
       "min   -1.156131e-01 -1.023071e-01 -7.639450e-02 -1.260971e-01 -1.377672e-01  \n",
       "25%   -3.035840e-02 -3.511716e-02 -3.949338e-02 -3.324559e-02 -3.317903e-02  \n",
       "50%   -3.819065e-03 -6.584468e-03 -2.592262e-03 -1.947171e-03 -1.077698e-03  \n",
       "75%    2.984439e-02  2.931150e-02  3.430886e-02  3.243232e-02  2.791705e-02  \n",
       "max    1.987880e-01  1.811791e-01  1.852344e-01  1.335973e-01  1.356118e-01  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading dataset\n",
    "X, y = datasets.load_diabetes(return_X_y = True , as_frame = True)\n",
    "\n",
    "# Checking value distributions\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2a730dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    151.0\n",
       "1     75.0\n",
       "2    141.0\n",
       "3    206.0\n",
       "4    135.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking fist 5 sample on target column\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01c1fa",
   "metadata": {},
   "source": [
    "As we see all values is normalised (in range from -1 to 1). This is prefer to do with linear models for better working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3d90be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting dataset on Train and test subsets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e696768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0e4550b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model on train subset\n",
    "\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "35c32016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5153335792084508"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking score (R^2)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5a580942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.05646134525746"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating more understandable score function\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def score_rmse(y_test, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "score_rmse(y_test, model2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2f62e821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.34911173998902"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking score (Root Mean Squared Error)\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "score_rmse(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ecbf7",
   "metadata": {},
   "source": [
    "We see that we are wrong on average by `52`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
